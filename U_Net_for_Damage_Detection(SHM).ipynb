{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## IC-SHM Damage Recognition Model\n",
        "Run the following cells till the first checkpoint for training"
      ],
      "metadata": {
        "id": "8teQ0Mtl7FaH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87BRfU-hrtwj"
      },
      "outputs": [],
      "source": [
        "#Importing the necessary libraries\n",
        "import platform\n",
        "print(\"Python version:\", platform.python_version())\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"tensorflow version:\",tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "print(\"numpy version:\",np.__version__)\n",
        "\n",
        "import cv2\n",
        "print(\"cv2 version:\",cv2.__version__)\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "print(\"matplotlib version:\",matplotlib.__version__)\n",
        "\n",
        "import pandas as pd\n",
        "print(\"pandas version:\",pd.__version__)\n",
        "\n",
        "from skimage.transform import resize\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "lGuzyNYlr8KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Monting G-Drive to access the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "id": "0PxeVbGrsEpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to change the path format \n",
        "def path_correct(path):\n",
        "  path = '/'.join(path[2:].split('\\\\'))\n",
        "  path = os.path.join(path_ds, path)\n",
        "  return path"
      ],
      "metadata": {
        "id": "QKpNckjqsFMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dU-6xP5D7922"
      },
      "outputs": [],
      "source": [
        "#function to put the label images into 3 channels\n",
        "def get_label(file_path):\n",
        "  \n",
        "    mask = np.squeeze(file_path, axis = 2)\n",
        "    target_array = np.zeros((mask.shape[0],mask.shape[1],3))\n",
        "    target_array[:,:,0]=np.where(mask == 1, 1, 0)\n",
        "    target_array[:,:,1]=np.where(mask == 2, 1, 0)\n",
        "    target_array[:,:,2]=np.where(mask == 3, 1, 0)\n",
        "    \n",
        "    return target_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0riRTcx_7923"
      },
      "outputs": [],
      "source": [
        "#function to normalize the images\n",
        "def normalize(input_image):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  return input_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fdNFjIFdO2h"
      },
      "outputs": [],
      "source": [
        "# Functions to plot the images and labels\n",
        "def show_img(image):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "\n",
        "def show_label(label):\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(16, 112))\n",
        "  y1 = label[:,:,0]\n",
        "  y2 = label[:,:,1]\n",
        "  y3 = label[:,:,2]\n",
        "  plt.axis('off')\n",
        "  axes[0].axis('off')\n",
        "  axes[1].axis('off')\n",
        "  axes[2].axis('off')\n",
        "  axes[0].imshow(y1)\n",
        "  axes[1].imshow(y2)\n",
        "  axes[2].imshow(y3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to print the prediction images\n",
        "def show_pred(y):\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(16, 112))\n",
        "  y1 = y[:,:,0]\n",
        "  y2 = y[:,:,1]\n",
        "  y3 = y[:,:,2]\n",
        "  plt.axis('off')\n",
        "  axes[0].axis('off')\n",
        "  axes[1].axis('off')\n",
        "  axes[2].axis('off')\n",
        "  axes[0].imshow(y1)\n",
        "  axes[1].imshow(y2)\n",
        "  axes[2].imshow(y3)"
      ],
      "metadata": {
        "id": "YLxlap45AWjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Checkpoint - 1\n",
        "Run untill here for training and testing both."
      ],
      "metadata": {
        "id": "_G2ee-W68ywQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oL__ayDl87Ka"
      },
      "outputs": [],
      "source": [
        "# Image and Label augmentation function \n",
        "def image_augmentation(img):\n",
        "  seed = (2,3)\n",
        "  img = tf.image.stateless_random_flip_left_right(img, seed) \n",
        "  return img\n",
        "\n",
        "def label_augmentation(img):\n",
        "  seed = (2,3)\n",
        "  img = tf.image.stateless_random_flip_left_right(img, seed)\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILCBhTg_8_mY"
      },
      "outputs": [],
      "source": [
        "# Preprocess function to run all the required preprocessing functions on the images\n",
        "def preprocess(x, y):\n",
        "    def f(x, y):\n",
        "        x = tf.io.read_file(x)\n",
        "        y = tf.io.read_file(y)\n",
        "        x = tf.io.decode_png(x, channels = 3)\n",
        "        x = tf.image.resize_with_pad(x, 256, 448)\n",
        "        x = tf.numpy_function(normalize, [x], [tf.float32])\n",
        "        y = tf.io.decode_bmp(y, channels = 0)\n",
        "        y = tf.numpy_function(get_label, [y], [tf.float32])\n",
        "        y = tf.image.resize_with_pad(y, 256, 448)\n",
        "        x = tf.numpy_function(image_augmentation, [x], [tf.float32])\n",
        "        y = tf.numpy_function(label_augmentation, [y], [tf.float32])\n",
        "        \n",
        "        return x, y\n",
        "\n",
        "    images, masks = tf.numpy_function(f, [x, y], [tf.float32, tf.float32])\n",
        "    images.set_shape([256, 448, 3])\n",
        "    masks.set_shape([256, 448, 3])\n",
        "\n",
        "    return images, masks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data pipeline function to cache dataset to ram for reducing the data loading bottleneck during training\n",
        "def tf_dataset(x, y, batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.shuffle(buffer_size=3000)\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls= tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch, num_parallel_calls= tf.data.AUTOTUNE)\n",
        "    dataset = dataset.cache()\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "7mKGm_bY9Kg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the training data for damage images\n",
        "\n",
        "#Access the csv file containing the absolute directory paths to each file\n",
        "path_ds = os.path.join('/content/drive/MyDrive/IC-SHM 2021','Tokaido_dataset') #put a path to the dataset\n",
        "col_names = ['image file name', 'component label file name', 'damage label file name', 'depth image file name', \n",
        "             'camera focal length in mm', 'regular images', 'images containing damage in the RRDR']\n",
        "ftrain = pd.read_csv(os.path.join(path_ds,'files_train.csv'),names = col_names,delimiter=',')\n",
        "ftrain.iloc[:,0] = ftrain.iloc[:,0].apply(lambda x: path_correct(x))\n",
        "ftrain.iloc[:,1] = ftrain.iloc[:,1].apply(lambda x: path_correct(x))\n",
        "ftrain.iloc[:,2] = ftrain.iloc[:,2].apply(lambda x: path_correct(x))\n",
        "ftrain.iloc[:,3] = ftrain.iloc[:,3].apply(lambda x: path_correct(x))\n",
        "train_comp = ftrain.loc[ftrain['regular images']==True, ['image file name', 'component label file name', 'damage label file name', 'depth image file name', 'camera focal length in mm']]\n",
        "train_dmg = ftrain.loc[ftrain['images containing damage in the RRDR']==True, ['image file name', 'component label file name', 'damage label file name', 'depth image file name', 'camera focal length in mm']]\n"
      ],
      "metadata": {
        "id": "ptSL5ldtsFQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd6fm9lSGITg"
      },
      "outputs": [],
      "source": [
        "#splitting the data for training and validation\n",
        "\n",
        "#Run for training on the damage images\n",
        "train1 = train_dmg[:4000]\n",
        "val1 = train_dmg[4000:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCBJaQcCKH4z"
      },
      "outputs": [],
      "source": [
        "# Creating the tf dataset from dataframe containing image addresses\n",
        "\n",
        "images = train1['image file name'].to_numpy()\n",
        "masks = train1['damage label file name'].to_numpy()\n",
        "dataset = tf_dataset(images, masks)\n",
        "images_val = val1['image file name'].to_numpy()\n",
        "masks_val = val1['damage label file name'].to_numpy()\n",
        "dataset_val = tf_dataset(images_val, masks_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing out an image for reference\n",
        "for x, y in dataset.take(1):\n",
        "        show_img(x[0])\n",
        "        show_label(y[0])\n",
        "        \n",
        "        break"
      ],
      "metadata": {
        "id": "mn86ceULsQXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Checkpoint - 2"
      ],
      "metadata": {
        "id": "upJMWQ7s98gC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the necessary Keras libraries for Creating the U-Net Model with gated attention and residual connections\n",
        "\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, Add, Dropout, UpSampling2D, Input, Multiply, MaxPooling2D, Concatenate\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "\n",
        "#number of features to be used in the model df for encoder and uf for decoder, 32 was found to be optimal for both\n",
        "df=32\n",
        "uf=32\n",
        "    \n",
        "def build_unet(input_shape):\n",
        "\n",
        "  #convolution block with batch normalization to be used in both encoder and decoder\n",
        "\n",
        "  def conv2d(layer_input,filters,dropout_rate=0):\n",
        "    d = Conv2D(filters,kernel_size=(3,3),strides=(1,1),padding='same')(layer_input)\n",
        "    d = BatchNormalization()(d)\n",
        "    d = Activation('relu')(d)\n",
        "      \n",
        "    d = Conv2D(filters,kernel_size=(3,3),strides=(1,1),padding='same')(d)\n",
        "    d = BatchNormalization()(d)\n",
        "    d = Activation('relu')(d)\n",
        "\n",
        "    d = Conv2D(filters,kernel_size=(3,3),strides=(1,1),padding='same')(d)\n",
        "    d = BatchNormalization()(d)\n",
        "\n",
        "    sc = Conv2D(filters,kernel_size=(1,1),padding='same')(layer_input)\n",
        "    sc = BatchNormalization()(sc)\n",
        "\n",
        "    rp = Add()([sc,d])\n",
        "    rp = Activation('relu')(rp)\n",
        "    rp = Dropout(dropout_rate)(rp)\n",
        "      \n",
        "    return rp\n",
        "\n",
        "  #convolution block without batch normalization to be used in both encoder and decoder\n",
        "\n",
        "  def conv2d_wobn(layer_input,filters,dropout_rate=0):\n",
        "    d = Conv2D(filters,kernel_size=(3,3),strides=(1,1),padding='same')(layer_input)\n",
        "    d = Activation('relu')(d)\n",
        "      \n",
        "    d = Conv2D(filters,kernel_size=(3,3),strides=(1,1),padding='same')(d)\n",
        "    d = Activation('relu')(d)\n",
        "\n",
        "    d = Conv2D(filters,kernel_size=(3,3),strides=(1,1),padding='same')(d)\n",
        "\n",
        "    sc = Conv2D(filters,kernel_size=(1,1),padding='same')(layer_input)\n",
        "\n",
        "    rp = Add()([sc,d])\n",
        "    rp = Activation('relu')(rp)\n",
        "    rp = Dropout(dropout_rate)(rp)\n",
        "\n",
        "    return rp\n",
        "    \n",
        "  #upsampling and convolution block with batch normalization to be used in decoder\n",
        "\n",
        "  def deconv2d(layer_input,filters):\n",
        "    u = UpSampling2D((2,2))(layer_input)\n",
        "    u = Conv2D(filters,kernel_size=(3,3),strides=(1,1),padding='same')(u)\n",
        "    u = BatchNormalization()(u)\n",
        "    u = Activation('relu')(u)\n",
        "\n",
        "    u = Conv2D(filters,kernel_size=(3,3),strides=(1,1),padding='same')(u)\n",
        "    u = BatchNormalization()(u)\n",
        "    u = Activation('relu')(u)\n",
        "      \n",
        "    return u\n",
        "\n",
        "  #attention block with batch normalization to be used in place of skip connections for gated attention\n",
        "\n",
        "  def attention_block(F_g,F_l,F_int):\n",
        "    g = Conv2D(F_int,kernel_size=(1,1),strides=(1,1),padding='valid')(F_g)\n",
        "    g = BatchNormalization()(g)\n",
        "    x = Conv2D(F_int,kernel_size=(1,1),strides=(1,1),padding='valid')(F_l)\n",
        "    x = BatchNormalization()(x)\n",
        "    psi = Add()([g,x])\n",
        "    psi = Activation('relu')(psi)\n",
        "    \n",
        "    psi = Conv2D(1,kernel_size=(1,1),strides=(1,1),padding='valid')(psi)\n",
        "      \n",
        "    psi = BatchNormalization()(psi)\n",
        "    psi = Activation('sigmoid')(psi)\n",
        "      \n",
        "    return Multiply()([F_l,psi])\n",
        "\n",
        "  #actual model definition depth = 4, i.e. 4 times downsampled by fator of 2 (by maxpooling)\n",
        "\n",
        "  inputs = Input(input_shape)\n",
        "    \n",
        "  conv1 = conv2d_wobn(inputs,df)\n",
        "  pool1 = MaxPooling2D((2,2))(conv1)\n",
        "    \n",
        "  conv2 = conv2d(pool1,df*2)\n",
        "  pool2 = MaxPooling2D((2,2))(conv2)\n",
        "    \n",
        "  conv3 = conv2d(pool2,df*4)\n",
        "  pool3 = MaxPooling2D((2,2))(conv3)\n",
        "    \n",
        "  conv4 = conv2d(pool3,df*8)\n",
        "  pool4 = MaxPooling2D((2,2))(conv4)\n",
        "  \n",
        "  conv5 = conv2d(pool4,df*8)\n",
        "    \n",
        "  up6 = deconv2d(conv5,uf*8)\n",
        "  conv6 = attention_block(up6,conv4,uf*8)\n",
        "  up6 = Concatenate()([up6,conv6])\n",
        "  conv6 = conv2d_wobn(up6,uf*8)\n",
        "  \n",
        "  up7 = deconv2d(conv6,uf*4)\n",
        "  conv7 = attention_block(up7,conv3,uf*4)\n",
        "  up7 = Concatenate()([up7,conv7])\n",
        "  conv7 = conv2d_wobn(up7,uf*4)\n",
        "    \n",
        "  up8 = deconv2d(conv7,uf*2)\n",
        "  conv8 = attention_block(up8,conv2,uf*2)\n",
        "  up8 = Concatenate()([up8,conv8])\n",
        "  conv8 = conv2d_wobn(up8,uf*2)\n",
        "    \n",
        "  up9 = deconv2d(conv8,uf)\n",
        "  conv9 = attention_block(up9,conv1,uf)\n",
        "  up9 = Concatenate()([up9,conv9])\n",
        "  conv9 = conv2d_wobn(up9,uf)\n",
        "\n",
        "  #here the first input to Conv2D i.e. 3 defines the output number of classes to be pridicted\n",
        "\n",
        "  outputs = Conv2D(3,kernel_size=(1,1),strides=(1,1),activation='sigmoid')(conv9)\n",
        "   \n",
        "  model = Model(inputs=inputs,outputs=outputs)\n",
        "    \n",
        "  return model"
      ],
      "metadata": {
        "id": "TtoNOhL1zh9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building the unet model with gated attention and residual connections and printing its summary\n",
        "model = build_unet((256,448,3))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "PHgKwHrJsQZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Checkpoint 3\n",
        "\n"
      ],
      "metadata": {
        "id": "15tou5W5-Dpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using Adam optimizer and fixing the learning rate \n",
        "optimizer_adam = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)"
      ],
      "metadata": {
        "id": "Ga8QoLn1sQdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checkpoint for model saving and reloading the saved weights\n",
        "# \"training_dmg_resatt_final/cp_dmg.ckpt\" this checkpoint to be supplied for best weights as trained by us\n",
        "checkpoint_path = os.path.join(path_ds, \"training_dmg_resatt_final/cp_dmg.ckpt\")\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,  monitor = 'iou', mode='max', save_best_only = True,\n",
        "                                                 verbose=1)"
      ],
      "metadata": {
        "id": "PlS5eyGYsFYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxZGVgdmHqT-"
      },
      "outputs": [],
      "source": [
        "\"\"\" Courtesy stackoverflow Daniel MÃ¶ller https://stackoverflow.com/users/2097240/daniel-m%c3%b6ller?tab=profile\n",
        "answer to question 'Custom loss function for U-net in keras using class weights: `class_weight` not supported for 3+ dimensional targets' \n",
        "\"\"\"\n",
        "# Weighted loss function \n",
        "def weightedLoss(originalLossFunc, weightsList):\n",
        "\n",
        "    def lossFunc(true, pred):\n",
        "\n",
        "        axis = -1 #if channels last \n",
        "        #axis=  1 #if channels first\n",
        "\n",
        "\n",
        "        #argmax returns the index of the element with the greatest value\n",
        "        #done in the class axis, it returns the class index    \n",
        "        classSelectors = K.argmax(true, axis=axis) \n",
        "            #if your loss is sparse, use only true as classSelectors\n",
        "\n",
        "        #considering weights are ordered by class, for each class\n",
        "        #true(1) if the class index is equal to the weight index   \n",
        "        classSelectors = [K.equal(i, classSelectors) for i in range(len(weightsList))]\n",
        "\n",
        "        #casting boolean to float for calculations  \n",
        "        #each tensor in the list contains 1 where ground true class is equal to its index \n",
        "        #if you sum all these, you will get a tensor full of ones. \n",
        "        classSelectors = [K.cast(x, K.floatx()) for x in classSelectors]\n",
        "\n",
        "        #for each of the selections above, multiply their respective weight\n",
        "        weights = [sel * w for sel,w in zip(classSelectors, weightsList)] \n",
        "\n",
        "        #sums all the selections\n",
        "        #result is a tensor with the respective weight for each element in predictions\n",
        "        weightMultiplier = weights[0]\n",
        "        for i in range(1, len(weights)):\n",
        "            weightMultiplier = weightMultiplier + weights[i]\n",
        "\n",
        "\n",
        "        #make sure your originalLossFunc only collapses the class axis\n",
        "        #you need the other axes intact to multiply the weights tensor\n",
        "        loss = originalLossFunc(true,pred) \n",
        "        loss = loss * weightMultiplier\n",
        "\n",
        "        return loss\n",
        "    return lossFunc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#summation of dice loss and cross entropy loss\n",
        "\n",
        "from keras import backend as K\n",
        "def DiceCELoss(targets, inputs, smooth=1e-6):\n",
        "    CE = tf.keras.metrics.binary_crossentropy(targets, inputs)\n",
        "    y_true_f=K.flatten(targets)\n",
        "    y_pred_f=K.flatten(inputs)\n",
        "    intersection=K.sum(y_true_f*y_pred_f)\n",
        "    dice_loss=1-((2*intersection) + smooth)/(K.sum(y_true_f*y_true_f)+K.sum(y_pred_f*y_pred_f)+ smooth)\n",
        "    dice_CE=dice_loss+CE\n",
        "    return dice_CE"
      ],
      "metadata": {
        "id": "vx_bPXfrsFb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#summation of log of (1-dice loss) and cross entropy loss\n",
        "\n",
        "import math\n",
        "from keras import backend as K\n",
        "def logDiceCELoss(targets, inputs, smooth=1e-6):\n",
        "    CE = tf.keras.metrics.binary_crossentropy(targets, inputs)\n",
        "    #CE = tf.keras.metrics.CategoricalCrossentropy(targets, inputs)\n",
        "    y_true_f=K.flatten(targets)\n",
        "    y_pred_f=K.flatten(inputs)\n",
        "    intersection=K.sum(y_true_f*y_pred_f)\n",
        "    dice_loss=1-((2*intersection) + smooth)/(K.sum(y_true_f*y_true_f)+K.sum(y_pred_f*y_pred_f)+ smooth)\n",
        "    dice_CE=CE-math.log(1-dice_loss)\n",
        "    return dice_CE"
      ],
      "metadata": {
        "id": "7rLf2ExfsFee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The weights for each class are hardcoded here and are calculated using the code presented towards the end of this notebook\n",
        "w1= 0.03611688490088685\n",
        "w2= 1.0\n",
        "w3=9.345573778790564"
      ],
      "metadata": {
        "id": "gpLmKHKvQwDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#best results were obtained with binary cross entropy loss \n",
        "\n",
        "model.compile(optimizer= optimizer_adam,\n",
        "              loss= weightedLoss(tf.keras.losses.BinaryCrossentropy(), [w1,w2,w3]),\n",
        "              metrics=[\n",
        "                       tf.keras.metrics.BinaryAccuracy(),\n",
        "                       tf.keras.metrics.Recall(thresholds = 0.2),\n",
        "                       tf.keras.metrics.Precision(thresholds = 0.7),\n",
        "                       tf.keras.metrics.MeanIoU(3,name=\"iou\")])"
      ],
      "metadata": {
        "id": "oqfQgRq4sFmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run this cell for loading the weights from saved checkpoints\n",
        "model.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "41Gaz7PYsFp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Checkpoint 4"
      ],
      "metadata": {
        "id": "ACqVJQqI_QLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "history = model.fit(dataset, epochs= 10 ,validation_data= dataset_val, verbose = 1, callbacks=[cp_callback])"
      ],
      "metadata": {
        "id": "YYNMUSH5sFsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print Loss\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.epoch, loss, 'r', label='Training loss')\n",
        "plt.plot(history.epoch, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GZRYmYq0sFvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print Binary Accuracy\n",
        "accu = history.history['binary_accuracy']\n",
        "val_accu = history.history['val_binary_accuracy']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.epoch, accu, 'r', label='Training binary accuracy')\n",
        "plt.plot(history.epoch, val_accu, 'b', label='Validation binary accuracy')\n",
        "plt.title('Training and Validation binary accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('binary accuracy Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KE2n4hShwjay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print recall\n",
        "recall = history.history['recall']\n",
        "val_recall = history.history['val_recall']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.epoch, recall, 'r', label='Training recall')\n",
        "plt.plot(history.epoch, val_recall, 'b', label='Validation recall')\n",
        "plt.title('Training and Validation recall')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('recall Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MV2YoqVAwjin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print precision\n",
        "pres = history.history['precision']\n",
        "val_pres = history.history['val_precision']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.epoch, pres, 'r', label='Training precision')\n",
        "plt.plot(history.epoch, val_pres, 'b', label='Validation precision')\n",
        "plt.title('Training and Validation precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('precision Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qvaFXaCOwjmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print Mean IoU\n",
        "miou = history.history['iou']\n",
        "val_miou = history.history['val_iou']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.epoch, miou, 'r', label='Training mean_io_u')\n",
        "plt.plot(history.epoch, val_miou, 'b', label='Validation mean_io_u')\n",
        "plt.title('Training and Validation mean_io_u')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('mean_io_u Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NgQY0pR2wjpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model on validation dataset\n",
        "model.evaluate(dataset_val, verbose = 1)"
      ],
      "metadata": {
        "id": "Ax32NbRY_dYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing predictions on the validation dataset\n",
        "z=1\n",
        "for x, y in dataset_val.take(10):\n",
        "        z += 1\n",
        "        show_img(x[2])\n",
        "        show_label(y[2])\n",
        "        pred = model.predict(x)\n",
        "        show_pred(pred[2])\n",
        "        if (z==9):\n",
        "          break"
      ],
      "metadata": {
        "id": "Zf3rAHVq_gps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Checkpoint 5"
      ],
      "metadata": {
        "id": "m1r84_RRAuJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing for the test dataset\n",
        "def preprocess_test(x,y):\n",
        "    def f(x,y):\n",
        "        x = tf.io.read_file(x)\n",
        "        y = tf.io.read_file(y)\n",
        "        x = tf.io.decode_png(x, channels = 3)\n",
        "        x = tf.image.resize_with_pad(x, 256,448)\n",
        "        x = tf.numpy_function(normalize, [x], [tf.float32]) \n",
        "        y = tf.io.decode_png(y, channels = 0)   \n",
        "        y = tf.numpy_function(get_label_tex, [y], [tf.float32])\n",
        "        y = tf.image.resize_with_pad(y, 256, 448)   \n",
        "\n",
        "        return x, y\n",
        "\n",
        "    images, masks = tf.numpy_function(f, [x, y], [tf.float32, tf.float32])\n",
        "    images.set_shape([256, 448, 3])\n",
        "    masks.set_shape([256, 448, 3])\n",
        "\n",
        "    return images, masks"
      ],
      "metadata": {
        "id": "JkDQ9Wqhwj18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwTNkEjumALc"
      },
      "outputs": [],
      "source": [
        "#dataloader for the test dataset\n",
        "def tf_dataset_test(x,y, batch = 8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(preprocess_test, num_parallel_calls= tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch, num_parallel_calls= tf.data.AUTOTUNE)\n",
        "    dataset = dataset.cache()\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GiM3H1e029i"
      },
      "outputs": [],
      "source": [
        "#Function to change the path format \n",
        "def path_correct_png(path):\n",
        "  path = '/'.join(path[2:].split('\\\\'))\n",
        "  path = os.path.join(path_ds, path)\n",
        "  path = path[:-4] + '.png'\n",
        "  return path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw-44oXqmlfJ"
      },
      "outputs": [],
      "source": [
        "# Loading the training data from the component demage test dataset file\n",
        "\n",
        "#Access the csv file containing the absolute directory paths to each file\n",
        "path_ds = os.path.join('/content/drive/MyDrive/IC-SHM 2021','Tokaido_dataset') #put a path to the dataset\n",
        "col_names = ['image file name', 'component label file name', 'damage label file name', 'depth image file name', \n",
        "             'camera focal length in mm', 'regular images', 'images containing damage in the RRDR']\n",
        "ftest = pd.read_csv(os.path.join(path_ds,'files_test.csv'),names = col_names,delimiter=',')\n",
        "ftest.iloc[:,0] = ftest.iloc[:,0].apply(lambda x: path_correct(x))\n",
        "ftest.iloc[:,1] = ftest.iloc[:,1].apply(lambda x: path_correct(x))\n",
        "ftest.iloc[:,2] = ftest.iloc[:,2].apply(lambda x: path_correct_png(x))\n",
        "ftest.iloc[:,3] = ftest.iloc[:,3].apply(lambda x: path_correct(x))\n",
        "test_comp = ftest.loc[ftest['images containing damage in the RRDR']==True, ['image file name', 'component label file name', 'damage label file name', 'depth image file name', 'camera focal length in mm']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xW67FKEP7ipg"
      },
      "outputs": [],
      "source": [
        "# creating dataloader for component damage images\n",
        "\n",
        "images_test = test_comp['image file name'].to_numpy()\n",
        "masks_test = test_comp['damage label file name'].to_numpy()\n",
        "dataset_test = tf_dataset_test(images_test,masks_test)\n",
        "address = test_comp['damage label file name'].apply(lambda x : os.path.split(x)[1]).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing predictions on the component damage test dataset\n",
        "z=1\n",
        "for x, y in dataset_test.take(10):\n",
        "        z += 1\n",
        "        show_img(x[0])\n",
        "        show_label(y[0])\n",
        "        pred = model.predict(x)\n",
        "        show_pred(pred[0])\n",
        "        if (z==9):\n",
        "          break"
      ],
      "metadata": {
        "id": "yzNQU6UIFio_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Checkpoint 6"
      ],
      "metadata": {
        "id": "TO6bzGXVFli_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0sfoyrC7ijg"
      },
      "outputs": [],
      "source": [
        "#Function to create the predictions remove the padding 2 pixels from top and 2 pixels from bottom and upscale them to size (360, 640) and then save in the drive folder\n",
        "#this cell saves pridiction on damage component test images\n",
        "from PIL import Image\n",
        "import imageio\n",
        "\n",
        "root_path = '/content/drive/MyDrive/IC-SHM 2021/Tokaido_dataset/Prediction_lab'\n",
        "\n",
        "def size_changer(img):\n",
        "  mask = np.zeros((360,640, img.shape[2]), dtype = np.uint8)\n",
        "  temp = np.where(img[:,:,0] > 0.5, 1, 0)\n",
        "  temp = cv2.resize(temp.astype('uint8'), dsize = (640,360), interpolation=cv2.INTER_CUBIC)\n",
        "  temp = np.where(temp > 0.5, 1, 0)\n",
        "  mask[:,:,0] = temp\n",
        "\n",
        "  temp = np.where(img[:,:,1] > 0.5, 1, 0)\n",
        "  temp = cv2.resize(temp.astype('uint8'), dsize = (640,360), interpolation=cv2.INTER_CUBIC)\n",
        "  temp = np.where(temp > 0.5, 2, 0)\n",
        "  mask[:,:,1] = temp\n",
        "\n",
        "  temp = np.where(img[:,:,2] > 0.5, 1, 0)\n",
        "  temp = cv2.resize(temp.astype('uint8'), dsize = (640,360), interpolation=cv2.INTER_CUBIC)\n",
        "  temp = np.where(temp > 0.5, 3, 0)\n",
        "  mask[:,:,2] = temp\n",
        "\n",
        "  return mask\n",
        "\n",
        "def crop(img):\n",
        "  img=img[2:254,:,:]\n",
        "  return img\n",
        "\n",
        "def mask_save(img, save_path):\n",
        "  path = os.path.join(root_path, 'synthetic/test/labdmg')\n",
        "  img=crop(img)\n",
        "  img = size_changer(img)\n",
        "  mask = img\n",
        "\n",
        "  output = np.zeros((mask.shape[0],mask.shape[1]), dtype = np.uint8)\n",
        "  output = np.argmax(mask, axis = 2)\n",
        "  output = output + 1\n",
        "\n",
        "  imageio.imwrite(os.path.join(path, save_path), output.astype('uint8'))\n",
        "\n",
        "  return None\n",
        "\n",
        "i = 0\n",
        "for item in dataset_test:\n",
        "  p = model.predict(item[0])\n",
        "  for j in range(len(p)):\n",
        "    mask_save(p[j], os.path.join(address[i]))\n",
        "    i += 1\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e93Utci4yqVo"
      },
      "outputs": [],
      "source": [
        "#Function to create the predictions remove the padding 2 pixels from top and 2 pixels from bottom and upscale them to size (360, 640) and then save in the drive folder\n",
        "#this cell saves pridiction on texture test images\n",
        "from PIL import Image\n",
        "import imageio\n",
        "\n",
        "root_path = '/content/drive/MyDrive/IC-SHM 2021/Tokaido_dataset/Prediction_lab'\n",
        "\n",
        "def size_changer(img):\n",
        "  mask = np.zeros((360,640, img.shape[2]), dtype = np.uint8)\n",
        "\n",
        "  mask = np.zeros((360,640, img.shape[2]), dtype = np.uint8)\n",
        "  temp = np.where(img[:,:,0] > 0.5, 1, 0)\n",
        "  temp = cv2.resize(temp.astype('uint8'), dsize = (640,360), interpolation=cv2.INTER_CUBIC)\n",
        "  temp = np.where(temp > 0.5, 1, 0)\n",
        "  mask[:,:,0] = temp\n",
        "\n",
        "  temp = np.where(img[:,:,1] > 0.4, 1, 0)\n",
        "  temp = cv2.resize(temp.astype('uint8'), dsize = (640,360), interpolation=cv2.INTER_CUBIC)\n",
        "  temp = np.where(temp > 0.5, 2, 0)\n",
        "  mask[:,:,1] = temp\n",
        "\n",
        "  temp = np.where(img[:,:,2] > 0.4, 1, 0)\n",
        "  temp = cv2.resize(temp.astype('uint8'), dsize = (640,360), interpolation=cv2.INTER_CUBIC)\n",
        "  temp = np.where(temp > 0.5, 3, 0)\n",
        "  mask[:,:,2] = temp\n",
        "\n",
        "  return mask\n",
        "\n",
        "def crop(img):\n",
        "  img=img[2:254,:,:]\n",
        "  return img\n",
        "\n",
        "def mask_save(img, save_path):\n",
        "  path = os.path.join(root_path, 'synthetic_puretex/labdmg')\n",
        "  img=crop(img)\n",
        "  img = size_changer(img)\n",
        "  mask = img\n",
        "\n",
        "  output = np.zeros((mask.shape[0],mask.shape[1]), dtype = np.uint8)\n",
        "  output = np.argmax(mask, axis = 2)\n",
        "  output = output + 1\n",
        "  \n",
        "  imageio.imwrite(os.path.join(path, save_path), output.astype('uint8'))\n",
        "  return None\n",
        "\n",
        "i = 0\n",
        "for item in dataset_test_tex:\n",
        "  p = model.predict(item[0])\n",
        "  for j in range(len(p)):\n",
        "    mask_save(p[j], os.path.join(address_tex[i]))\n",
        "    i += 1\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code to find the percentage of pixels of each class \n",
        "import skimage.io\n",
        "p_of_class_1_pix=0\n",
        "p_of_class_2_pix=0\n",
        "p_of_class_3_pix=0\n",
        "\n",
        "for i in range(len(masks)):\n",
        "  img = skimage.io.imread(masks[i])\n",
        "  #plt.imshow(img)\n",
        "  #print(img.shape)\n",
        "  \n",
        "  # counting the number of pixels\n",
        "  p_of_class_1_pix = p_of_class_1_pix+((np.sum(img == 1)/(360*640))*100)\n",
        "  p_of_class_2_pix = p_of_class_2_pix+((np.sum(img == 2)/(360*640))*100)\n",
        "  p_of_class_3_pix = p_of_class_3_pix+((np.sum(img == 3)/(360*640))*100)\n",
        "\n",
        "\n",
        "p_of_class_1_pix=p_of_class_1_pix/len(masks)\n",
        "p_of_class_2_pix=p_of_class_2_pix/len(masks)\n",
        "p_of_class_3_pix=p_of_class_3_pix/len(masks)\n",
        "\n",
        "\n",
        "print('Number of class 1 pixels:', p_of_class_1_pix)\n",
        "print('Number of class 2 pixels:', p_of_class_2_pix)\n",
        "print('Number of class 3 pixels:', p_of_class_3_pix)"
      ],
      "metadata": {
        "id": "BzU332asG9z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code to find the weights needed for the weighted loss function\n",
        "#for median frequency weighting percentage of class 2 is median\n",
        "w1 = p_of_class_2_pix/p_of_class_1_pix\n",
        "w2 = p_of_class_2_pix/p_of_class_2_pix\n",
        "w3 = p_of_class_2_pix/p_of_class_3_pix\n",
        "\n",
        "print(w1,w2,w3)"
      ],
      "metadata": {
        "id": "8loiBcchHnCK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}